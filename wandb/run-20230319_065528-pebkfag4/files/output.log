
Traceback (most recent call last):
  File "/home/tonydeleon/sp23-nmep-hw1/main.py", line 269, in <module>
    main(config)
  File "/home/tonydeleon/sp23-nmep-hw1/main.py", line 105, in main
    train_acc1, train_loss = train_one_epoch(config, model, criterion, data_loader_train, optimizer, epoch)
  File "/home/tonydeleon/sp23-nmep-hw1/main.py", line 156, in train_one_epoch
    outputs = model(samples)
  File "/home/tonydeleon/miniconda3/envs/vision-zoo/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/tonydeleon/sp23-nmep-hw1/models/resnet.py", line 98, in forward
    x = F.relu(self.bn1(self.conv1(x)))
  File "/home/tonydeleon/miniconda3/envs/vision-zoo/lib/python3.10/site-packages/torch/nn/functional.py", line 1457, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 4.00 GiB (GPU 0; 10.76 GiB total capacity; 8.23 GiB already allocated; 1.46 GiB free; 8.25 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF